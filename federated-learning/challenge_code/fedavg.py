import argparse
import unittest
import warnings
from copy import deepcopy
from typing import List, Literal, Tuple

import torch
from opacus import PrivacyEngine
from torch.utils.data import DataLoader, TensorDataset

INPUT_DIM = 8
NUM_E2E_RUNS = 5



# suppress specific Opacus warnings
warnings.filterwarnings(
    "ignore",
    message="A ``sample_rate`` has been provided.*",
    category=UserWarning,
    module='opacus'
)

warnings.filterwarnings(
    "ignore",
    message="Secure RNG turned off.*",
    category=UserWarning,
    module='opacus'
)

# suppress PyTorch FutureWarning
warnings.filterwarnings(
    "ignore",
    category=FutureWarning,
    module='torch.nn.modules.module'
)



# Creating a small PyTorch model with 2 hidden layers and a ReLU activation function
# that can be trained to model the distribution of the data generated by the
# _generate_training_batch function.
class SimpleNN(torch.nn.Module):
    def __init__(self):
        super(SimpleNN, self).__init__()
        self.fc1 = torch.nn.Linear(INPUT_DIM, 64)  # first hidden layer
        self.fc2 = torch.nn.Linear(64, 16)  # second hidden layer
        self.fc3 = torch.nn.Linear(16, 2)   # output layer for binary classification
        self.relu = torch.nn.ReLU()
        
    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        return x

def _generate_training_batch(
    batch_size: int, input_dim: int
) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    Generate a random input/label pair to use as input to the model.

    There are 2 classes, and a sample's class is determined by the sum of its values
    against a fixed threshold.
    """
    sample_shape = [batch_size, input_dim]
    input_sample = torch.randn(*sample_shape)
    label = (input_sample.view(batch_size, -1).sum(dim=1) > 0.325).long()
    return input_sample, label


def validate_model(model: SimpleNN, num_samples: int = 32):
    """
    Validate a provided model against unseen data.

    Generates a new batch of training data (default 32 samples), runs a forward pass of the
    server model and compares the predictions against the labels.

    Input:
        model: A SimpleNN model which will be evaluated against new data

    Returns:
        The proportion of correct predictions
    """
    new_sample, targets = _generate_training_batch(num_samples, INPUT_DIM)

    result = model(new_sample)
    _, prediction = torch.max(result, dim=1)
    return sum(targets == prediction) / prediction.numel()


class Gateway:
    def __init__(
	self, name: str, batches_per_round: int = 4,
	noise_add_level: Literal["sample", "batch"] = "sample",
	noise_multiplier: float = 0.01, max_grad_norm: float = 1.0,
    ):
        self.model = SimpleNN()
        self.name = name
        self.batches_per_round = batches_per_round

        # initialise the optimizer and criterion here
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)
        self.criterion = torch.nn.CrossEntropyLoss()

        # initialise differential privacy parameters
        self.noise_multiplier = noise_multiplier
        self.max_grad_norm = max_grad_norm
        self.noise_add_level = noise_add_level

        if self.noise_add_level == "sample":
            # initialize Opacus PrivacyEngine
            self.privacy_engine = PrivacyEngine(
                self.model,
                sample_rate = 1.0 / self.batches_per_round,
                noise_multiplier = self.noise_multiplier,
                max_grad_norm = self.max_grad_norm,
            )
            
            # attach the PrivacyEngine to optimizer
            self.privacy_engine.attach(self.optimizer)
        
    def fed_round(self):
        """
        Perform a single federation round of training using randomly generated data.

        This function should run a forward pass through the SimpleNN model, calculate the
        loss and update the optimizer.
        """
        for _ in range(self.batches_per_round):
            batch, targets = _generate_training_batch(8, INPUT_DIM)
            
            self.optimizer.zero_grad()
            output = self.model(batch)
            loss = self.criterion(output, targets)
            loss.backward()

            if self.noise_add_level == "batch":
                # add differential privacy by adding noise to gradients
                self._perturb_params_for_differential_privacy_per_batch()
    
            self.optimizer.step()
        

    def update_model(self, state_dict: dict):
        """Update the gateway's local model with a new set of weights"""
        self.model.load_state_dict(state_dict)

    
    def _perturb_params_for_differential_privacy_per_batch(self):
        """
        Add noise to model gradients to obfuscate the original values.
        Gradients are also clipped to prevent large ones dominating noise.
        
        Args:
            model: model under training, containing gradients to be modified
            noise_multiplier: factor by which to multiply N(0,1) noise before adding
        """
	# clip gradients with L2 norm
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=self.max_grad_norm, norm_type=2.0)

        # add Gaussian noise
        for param in self.model.parameters():
            param.grad += torch.randn_like(param.grad) * self.noise_multiplier


class Orchestrator:
    def __init__(self, gateways: List[Gateway]):
        self.gateways = gateways
        self._server_model = None

    def train_fed_avg(self, num_rounds: int):
        """
        Perform a federated training run for `num_rounds` rounds.

        Input:
            num_rounds: The number of training rounds to perform

        Returns:
            An aggregated model
        """
        # initialise the server model at the start of the training
        self._server_model = SimpleNN()

        for _ in range(num_rounds):
            # update all gateways to the server model weights
            self._update_gateways(self._server_model.state_dict())
        
            # run a local training round in each gateway
            for gw in self.gateways:
                gw.fed_round()
        
            # aggregate the models from all gateways
            aggregated_state_dict = self._aggregate()
        
            # update server model with aggregated weights
            self._server_model.load_state_dict(aggregated_state_dict)

        return self._server_model

    def _aggregate(self) -> dict:
        """
        Iterates through all gateways connected to the orchestrator, reading each model's
        state_dict, and taking the average of the weights across the models.

        e.g.:

        state_dict = {
            "fc1.weight': torch.Tensor(...),
            "fc1.bias': torch.Tensor(...),
            "fc2.weight': torch.Tensor(...),
            "fc2.bias': torch.Tensor(...)
        }

        Returns:
            A state dict containing the averaged weights
        """
        # initialise state dict where we will store aggregated weights
        aggregated_state_dict = {}

        # fill the aggregated_state_dict with zeros as initial param values
        for key, param in self.gateways[0].model.state_dict().items():
            aggregated_state_dict[key] = torch.zeros_like(param)
    
        # compute sums for each param across the gateway state-dicts
        for gw in self.gateways:
            state_dict = gw.model.state_dict()
            for key, param in state_dict.items():
                aggregated_state_dict[key] += param
    
        # take the average for each param
        num_gateways = len(self.gateways)
        for key in aggregated_state_dict:
            aggregated_state_dict[key] /= num_gateways

        return aggregated_state_dict

    def _update_gateways(self, state_dict: dict):
        """
        Update all gateways' models with the provided state dict
        """
        for gw in self.gateways:
            gw.update_model(state_dict)


def complete_e2e_run(noise_add_level: Literal["sample", "batch"] = "sample"):
    gateways = [
        Gateway(f"gateway_{i}", 4, noise_add_level=noise_add_level) for i in range(4)
    ]

    orch = Orchestrator(gateways)

    new_model = orch.train_fed_avg(num_rounds=32)

    validation_accuracy = validate_model(new_model, num_samples=32)
    
    print(f"Run {i+1}/{NUM_E2E_RUNS} -- Training Complete. Validation accuracy: {validation_accuracy*100:.2f}%")




class TestFederatedLearning(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        # Suppress specific warnings during tests
        warnings.simplefilter("ignore", UserWarning)
        warnings.simplefilter("ignore", FutureWarning)

    def test_gateway_fed_round_updates(self):
        """Test that gateway.fed_round() updates model parameters."""
        gateway = Gateway("test_gateway", batches_per_round=1, noise_multiplier=0.0)
        
        initial_state_dict = deepcopy(gateway.model.state_dict())
        gateway.fed_round()  # perform one training round
        updated_state_dict = gateway.model.state_dict()

        for key in initial_state_dict:
            # assert that all weights changed
            self.assertFalse(torch.equal(initial_state_dict[key], updated_state_dict[key]),
                             f"Parameter {key} did not update as expected.")

        print("test_gateway_fed_round_updates passed.")

    
    def test_differential_privacy_noise_addition_per_batch(self):
        from scipy.stats import ttest_rel, wilcoxon
        import numpy as np
        
        """Test that noise is added to all the gradients."""
        gateway = Gateway("test_gateway", batches_per_round=1, noise_multiplier=1.0, noise_add_level="batch")

        batch, targets = _generate_training_batch(8, INPUT_DIM)
    
        # perform a forward and backward pass to get gradients
        output = gateway.model(batch)
        loss = gateway.criterion(output, targets)
        loss.backward()

        # store original gradients before adding noise
        gradients_before_noise = [param.grad.clone() for param in gateway.model.parameters()]

        # apply the differential privacy technique
        gateway._perturb_params_for_differential_privacy_per_batch()

        # capture the raw gradients after noise addition
        gradients_after_noise = [param.grad.clone() for param in gateway.model.parameters()]
        
        
        # check percentage change for each gradient

        epsilon = 1e-6 # threshold to avoid division by zero in percentage change calculation
        minimum_percentage_change = 2.0
        
        for grad_before, grad_after in zip(gradients_before_noise, gradients_after_noise):
            # flatten the gradients for easier comparison
            grad_before_flat = grad_before.view(-1)
            grad_after_flat = grad_after.view(-1)
    
            # calculate percentage change in each gradient
            percentage_change = torch.abs(grad_after_flat - grad_before_flat) / (torch.abs(grad_before_flat) + epsilon) * 100
    
            # ensure that every gradient has more than 2% change
            self.assertTrue(torch.all(percentage_change > minimum_percentage_change),
                            "Not all gradients have significant changes after noise addition.")
        
        print("test_differential_privacy_noise_addition_per_batch passed.")

    
    def test_aggregation_correctness(self):
        """Test that aggregation correctly computes the mean of gateway model weights."""
        gateways = [Gateway(f"gateway_{i}") for i in range(4)]
        
        # initialise first two gateways with all zeros and last two with all ones
        for gw in gateways[:2]:
            for param in gw.model.parameters():
                param.data.fill_(0.0)
        for gw in gateways[2:]:
            for param in gw.model.parameters():
                param.data.fill_(1.0)

        # perform the aggregation
        orch = Orchestrator(gateways)
        aggregated_state_dict = orch._aggregate()
        
        for key in aggregated_state_dict:
            # expected mean is (2*0 + 2*1) / 4 = 0.5
            expected = torch.full_like(aggregated_state_dict[key], 0.5)
            self.assertTrue(torch.allclose(aggregated_state_dict[key], expected),
                            f"Aggregation failed for {key}. Expected 0.5, got {aggregated_state_dict[key].mean().item()}")
        print("test_aggregation_correctness passed.")




if __name__ == "__main__":

    # set up argument parser
    parser = argparse.ArgumentParser(description="Run the complete script including unit-tests and 5 runs of e2e training + validation.")
    parser.add_argument('--noise-level', choices=['batch', 'sample'], required=True,
                        help='Specify "batch" for per-batch privacy or "sample" for per-sample privacy.')
    # parse arguments
    args = parser.parse_args()

    # run unit-tests
    unittest.main(argv=[''], exit=False)

    #Â run training and validation
    for i in range(NUM_E2E_RUNS):
        complete_e2e_run(args.noise_level)
